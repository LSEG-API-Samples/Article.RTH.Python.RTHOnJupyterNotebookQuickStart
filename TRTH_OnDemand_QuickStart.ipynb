{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick History on Jupyter Notebook Quick Start\n",
    "\n",
    "This article will demonstrate how to request tick history data on demand on Jupyter Notebook.\n",
    "\n",
    "## What is TRTH?\n",
    "\n",
    "[TRTH or Thomson Reuters Tick History](https://en.wikipedia.org/wiki/Representational_state_transfer)  is an Internet-hosted product on [DataScope Select platform or DSS](https://developers.refinitiv.com/datascope-select-dss). TRTH is a historical market data service, offering global data dating back to January 1996 . For example, intraday summaries, end of days prices, time and sales, market depth and raw data. TRTH provides  [REST API](https://en.wikipedia.org/wiki/Representational_state_transfer) to access all data. In this article, I will demonstrate how to retreive intraday summaries using an on demand request.\n",
    "\n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/TRTH_80.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Python 3.6 or higher\n",
    "- Jupyter Notebook\n",
    "- DSS username and password which is permissioned for TRTH content. To obtain DSS account, please contact Refinitiv account team for process and details.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The steps and Python source code to request TRTH content on demand are listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Request authentication token with DSS username and password.\n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Send HTTP post with DSS username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter DSS username:9010004\n",
      "Enter DSS Password:········\n",
      "the application received the response for authentication request.\n"
     ]
    }
   ],
   "source": [
    "import getpass as gp\n",
    "import requests\n",
    "import json\n",
    "\n",
    "username=input('Enter DSS username:')\n",
    "password=gp.getpass('Enter DSS Password:')\n",
    "\n",
    "requestUrl = \"https://hosted.datascopeapi.reuters.com/RestApi/v1/Authentication/RequestToken\"\n",
    "requestHeaders={\n",
    "    \"Prefer\":\"respond-async\",\n",
    "    \"Content-Type\":\"application/json\"\n",
    "    }\n",
    "requestBody={\n",
    "    \"Credentials\": {\n",
    "    \"Username\": username,\n",
    "    \"Password\": password\n",
    "  }\n",
    "}\n",
    "authenticationResp = requests.post(requestUrl, json=requestBody,headers=requestHeaders)\n",
    "print(\"the application received the response for authentication request.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if the status code of the response is 200. If yes, the request has succeeded so the application extracts and prints the authentication token. Otherwise, it prints the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication token (valid 24 hours):\n",
      "_x4k2g-emJDy0DqFLB7DlvYCX3tzxz2YJ0rqoxx95-taZ8NtwZihs0RDN3iPlVERki6aroqhbE1yaOyuC4joyIVNYZ2hpYB7o2aU8em4cNfrUfs0TfXbZNpQ74Xe7Ym9kO5TxugN1VKqnSHMLCpFUDByZ92zMBTXTunCWSuZPTbrG-nzrOq8625I4r49kxFlinyAFU825OH8jGZLZN2y5Kg1aSA4Q83-3KC7O3a0xXTcHuNBmxS3Kuh-JPaZMcklBJFIWkNsS_4DKqUixc6D7-Pj0gATQYAQBnAGUTSsfeIc\n"
     ]
    }
   ],
   "source": [
    "if authenticationResp.status_code == 200 :\n",
    "    jsonResponse = json.loads(authenticationResp.text.encode('ascii', 'ignore'))\n",
    "    token = jsonResponse[\"value\"]\n",
    "    print ('Authentication token (valid 24 hours):')\n",
    "    print (token)\n",
    "else:\n",
    "    print(\"Status Code:\",authenticationResp.status_code,\"\\n Text:\",json.dumps(json.loads(authenticationResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Request for data type using the received authentication token \n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step2_new.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Send HTTP post with on demand extraction request to request for data type. \n",
    " \n",
    "   The applications requests for intraday summaries. For more details of the others tick history data types(reports) and their fields, please see in [Data Dictionary - Custom Reporting](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=40731&type=documentation_item)  \n",
    "  \n",
    "   You can see all parameters of each data type in **REST API Reference Tree** at **https://hosted.datascopeapi.reuters.com/RestApi.Help/Home/RestApiProgrammingSdk**. You need to login with DSS username and password to access this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the application received the response for on demand extraction request.\n"
     ]
    }
   ],
   "source": [
    "requestUrl='https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/ExtractRaw'\n",
    "requestHeaders={\n",
    "    \"Prefer\":\"respond-async\",\n",
    "    \"Content-Type\":\"application/json\",\n",
    "    \"Authorization\": \"token \" + token\n",
    "}\n",
    "requestBody={\n",
    "  \"ExtractionRequest\": {\n",
    "    \"@odata.type\": \"#ThomsonReuters.Dss.Api.Extractions.ExtractionRequests.TickHistoryIntradaySummariesExtractionRequest\",\n",
    "    \"ContentFieldNames\": [\"Open\",\"High\",\"Low\",\"Last\",\"Volume\"],\n",
    "    \"IdentifierList\": {\n",
    "      \"@odata.type\": \"#ThomsonReuters.Dss.Api.Extractions.ExtractionRequests.InstrumentIdentifierList\",  \n",
    "      \"InstrumentIdentifiers\": [\n",
    "        {\"Identifier\": \"ADVANC.BK\", \"IdentifierType\": \"Ric\"},\n",
    "        {\"Identifier\": \"PTT.BK\", \"IdentifierType\": \"Ric\"} \n",
    "      ],\n",
    "      \"UseUserPreferencesForValidationOptions\":\"false\"    \n",
    "    },  \n",
    "    \"Condition\": {\n",
    "      \"MessageTimeStampIn\": \"GmtUtc\",\n",
    "      \"ReportDateRangeType\": \"Range\",\n",
    "      \"QueryStartDate\": \"2019-09-03T09:30:00.000Z\",\n",
    "      \"QueryEndDate\":   \"2019-09-03T17:00:00.000Z\",\n",
    "      \"SummaryInterval\": \"FifteenMinutes\",\n",
    "      \"TimebarPersistence\":\"true\",\n",
    "      \"DisplaySourceRIC\":\"true\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "extractionResp = requests.post(requestUrl, json=requestBody,headers=requestHeaders)\n",
    "print(\"the application received the response for on demand extraction request.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Check the request status  \n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step3.png\">\n",
    " \n",
    "- If the HTTP status code of response is 202 this means the extraction request was accepted, but processing has not completed yet. Hence, the application gets the received location url from 202 response header received in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP status of the response: 202\n",
      "Extraction is not complete, the application will poll the location URL:\n",
      "https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/ExtractRawResult(ExtractionId='0x06cba0180740f97d')\n"
     ]
    }
   ],
   "source": [
    "requestStatus =  extractionResp.status_code\n",
    "print (\"HTTP status of the response: \" + str(requestStatus))\n",
    "requestUrl=None\n",
    "if requestStatus == 202 :\n",
    "    requestUrl = extractionResp.headers[\"location\"]\n",
    "    print ('Extraction is not complete, the application will poll the location URL:')\n",
    "    print (str(requestUrl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While the status of the extaction request is 202, poll the request status every 30 seconds using the location url got from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we received a 202, we wait 30 seconds, then poll again until we do not receive 202\n",
      "HTTP status of the response: 200\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while (requestStatus == 202):\n",
    "    print ('As we received a 202, we wait 30 seconds, then poll again until we do not receive 202')\n",
    "    time.sleep(30)\n",
    "    extractionResp = requests.get(requestUrl,headers=requestHeaders)\n",
    "    requestStatus= extractionResp.status_code\n",
    "    print ('HTTP status of the response: ' + str(requestStatus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the request is completed(The HTTP stauts code is not 202), check the status code. If it is 200 or OK, the application gets and prints the results which are jobId and the extraction notes. The jobId is used to retrieve the data while the extreaction can be used to analyse data or troubleshooting problems. Apart from the HTTP status code 200, it is an error and the application prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jobId: 0x06cba0180740f97d\n",
      "\n",
      "Extraction notes:\n",
      "Extraction Services Version 13.1.40889 (ec84d57d2aa3), Built Jul 17 2019 13:34:00\n",
      "User ID: 9010004\n",
      "Extraction ID: 2000000100128338\n",
      "Schedule: 0x06cba0180740f97d (ID = 0x0000000000000000)\n",
      "Input List (1 items):  (ID = 0x06cba0180740f97d) Created: 09/19/2019 09:28:42 Last Modified: 09/19/2019 09:28:42\n",
      "Report Template (5 fields): _OnD_0x06cba0180740f97d (ID = 0x06cba0180970f97d) Created: 09/19/2019 09:27:07 Last Modified: 09/19/2019 09:27:07\n",
      "Schedule dispatched via message queue (0x06cba0180740f97d), Data source identifier (DA265F29E6074240812FA665E7FCFABB)\n",
      "Schedule Time: 09/19/2019 09:27:09\n",
      "Processing started at 09/19/2019 09:27:09\n",
      "Processing completed successfully at 09/19/2019 09:28:42\n",
      "Extraction finished at 09/19/2019 02:28:42 UTC, with servers: tm04n01, TRTH (63.361 secs)\n",
      "Instrument <RIC,PTT.BK> expanded to 1 RIC: PTT.BK.\n",
      "Total instruments after instrument expansion = 1\n",
      "Quota Message: INFO: Tick History Cash Quota Count Before Extraction: 510; Instruments Approved for Extraction: 1; Tick History Cash Quota Count After Extraction: 510, 102% of Limit; Tick History Cash Quota Limit: 500\n",
      "Manifest: #RIC,Domain,Start,End,Status,Count\n",
      "Manifest: PTT.BK,Market Price,2019-09-03T02:30:00.000000000Z,2019-09-03T09:45:00.000000000Z,Active,30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if requestStatus == 200 :\n",
    "    extractionRespJson = json.loads(extractionResp.text.encode('ascii', 'ignore'))\n",
    "    jobId = extractionRespJson[\"JobId\"]\n",
    "    print ('\\njobId: ' + jobId + '\\n')\n",
    "    notes = extractionRespJson[\"Notes\"]\n",
    "    print ('Extraction notes:\\n' + notes[0])\n",
    "else:\n",
    "    print(\"Status Code:\",extractionResp.status_code,\"\\n Text:\",json.dumps(json.loads(extractionResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Retrieve data\n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step4_complete.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Send HTTP get with a JobID got from the 200 OK response to retrieve data from TRTH or AWS \n",
    "\n",
    "   TRTH provides downloading some extraction data directly from Amazon Web Services(AWS) where the data files are hosted. The tick history data types which are supported by this features are:\n",
    "    * Time and Sales\n",
    "    * Market Depth\n",
    "    * Intraday Summaries\n",
    "    * Raw.\n",
    "\n",
    "  This sample requests for intraday summaries which AWS download supports.  Therefore, I will download data from AWS which delivers faster downloads than TRTH. The application must include the HTTP header field X-Direct-Download true to specify for the download to occur through AWS. When the application sends the requst with X-Direct-Download: true header, it will receive a response with HTTP status 302 or redirect. The response header contains a redirection URI in item Location. Fortunately, Python application automatically follow the redirection so the appliation have nothing to do. A call is made in the background to this URI and the data is retrieved. \n",
    "  If you application does not perform redirection automatically, please follows [Advisory: Directly Downloading from Amazon Generates Error](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=25898&type=documentation_item) how to perfrom redirection manually and to protect the error from AWS download.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the application received the response for retreiving data from the jobId.\n"
     ]
    }
   ],
   "source": [
    "DownloadFromAWS = False\n",
    "requestUrl = \"https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/RawExtractionResults\" + \"('\" + jobId + \"')\" + \"/$value\"\n",
    "requestHeaders={\n",
    "        \"Prefer\":\"respond-async\",\n",
    "        \"Content-Type\":\"text/plain\",\n",
    "        \"Accept-Encoding\":\"gzip\",\n",
    "        \"Authorization\": \"token \" + token\n",
    "}\n",
    "if DownloadFromAWS==True:\n",
    "    requestHeaders.update({\"X-Direct-Download\":\"true\"})\n",
    "dataRetrieveResp=requests.get(requestUrl,headers=requestHeaders,stream=True)\n",
    "print(\"the application received the response for retreiving data from the jobId.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the status is 200 or OK that means the application can retreive data from TRTH or AWS sucessfully. Otherwise, it prints the error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataRetrieveResp.status_code == 200 :\n",
    "    print ('The application retrieve data from the server successfully.')\n",
    "else:\n",
    "    print(\"Status Code:\",extractionResp.status_code,\"\\n Text:\",json.dumps(json.loads(extractionResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To avoid data lost issues especially with large data sets. The application should dowload compressed data and save it before decompressing it instead of decompressing it on the fly. For more information, please refer to [Advisory: Avoid Incomplete Output - Download then Decompress](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=22738&type=documentation_item)\n",
    "\n",
    "   In Python, you can ensure that the data is not automatically decompressed on the fly by setting *Response.raw.decode_content* to be *false*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving compressed data to file:C:\\Users\\u8007607\\JupyterNoteBook\\TRTH_Python_JupyterNotebook\\compressData.csv.gz ... please be patient\n",
      "Finished saving compressed data to file:C:\\Users\\u8007607\\JupyterNoteBook\\TRTH_Python_JupyterNotebook\\compressData.csv.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "dataRetrieveResp.raw.decode_content = False\n",
    "fileName= os.getcwd() + \"\\compressData.csv.gz\" \n",
    "print ('Saving compressed data to file:' + fileName + ' ... please be patient')\n",
    "\n",
    "chunk_size = 1024\n",
    "rr = dataRetrieveResp.raw\n",
    "with open(fileName, 'wb') as fd:\n",
    "    shutil.copyfileobj(rr, fd, chunk_size)\n",
    "fd.close\n",
    "\n",
    "print ('Finished saving compressed data to file:' + fileName + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In production, you should handle the data line by line instead of store all the data in one variable. This is to avoid issues with large data sets.\n",
    "  \n",
    "  To display some data lines, the application reads and decompress some lines in the data file just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from file, and decompress at most 10 lines of it:\n",
      "#RIC,Alias Underlying RIC,Domain,Date-Time,GMT Offset,Type,Open,High,Low,Last,Volume\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T02:30:00.000000000Z,+7,Intraday 15Min,,,,,\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T02:45:00.000000000Z,+7,Intraday 15Min,43.5,43.75,43.5,43.75,463600\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T03:00:00.000000000Z,+7,Intraday 15Min,43.5,43.75,43.25,43.5,4247200\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T03:15:00.000000000Z,+7,Intraday 15Min,43.5,43.5,43.25,43.25,431900\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T03:30:00.000000000Z,+7,Intraday 15Min,43.5,43.5,43.25,43.25,453600\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T03:45:00.000000000Z,+7,Intraday 15Min,43.25,43.5,43.25,43.5,790900\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T04:00:00.000000000Z,+7,Intraday 15Min,43.25,43.5,43.25,43.5,128700\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T04:15:00.000000000Z,+7,Intraday 15Min,43.5,43.5,43.25,43.25,218200\n",
      "\n",
      "PTT.BK,,Market Price,2019-09-03T04:30:00.000000000Z,+7,Intraday 15Min,43.25,43.5,43.25,43.5,2358900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "maxLines = 10\n",
    "print ('Read data from file, and decompress at most ' + str(maxLines) + ' lines of it:')\n",
    "uncompressedData = \"\"\n",
    "count = 0\n",
    "with gzip.open(fileName, 'rb') as fd:\n",
    "    for line in fd:\n",
    "        dataLine = line.decode(\"utf-8\")\n",
    "        print (dataLine)\n",
    "        uncompressedData = uncompressedData + dataLine\n",
    "        count += 1\n",
    "        if count >= maxLines:\n",
    "            break\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the same data as the previous step in a pretty format(table) using a pandas dataframe. This is optional step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#RIC</th>\n",
       "      <th>Alias Underlying RIC</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Date-Time</th>\n",
       "      <th>GMT Offset</th>\n",
       "      <th>Type</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T02:30:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T02:45:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.75</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.75</td>\n",
       "      <td>463600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T03:00:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.75</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>4247200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T03:15:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.25</td>\n",
       "      <td>431900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T03:30:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.25</td>\n",
       "      <td>453600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T03:45:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>790900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T04:00:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>128700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T04:15:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.25</td>\n",
       "      <td>218200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PTT.BK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Price</td>\n",
       "      <td>2019-09-03T04:30:00.000000000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>Intraday 15Min</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>2358900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #RIC  Alias Underlying RIC        Domain                       Date-Time  \\\n",
       "0  PTT.BK                   NaN  Market Price  2019-09-03T02:30:00.000000000Z   \n",
       "1  PTT.BK                   NaN  Market Price  2019-09-03T02:45:00.000000000Z   \n",
       "2  PTT.BK                   NaN  Market Price  2019-09-03T03:00:00.000000000Z   \n",
       "3  PTT.BK                   NaN  Market Price  2019-09-03T03:15:00.000000000Z   \n",
       "4  PTT.BK                   NaN  Market Price  2019-09-03T03:30:00.000000000Z   \n",
       "5  PTT.BK                   NaN  Market Price  2019-09-03T03:45:00.000000000Z   \n",
       "6  PTT.BK                   NaN  Market Price  2019-09-03T04:00:00.000000000Z   \n",
       "7  PTT.BK                   NaN  Market Price  2019-09-03T04:15:00.000000000Z   \n",
       "8  PTT.BK                   NaN  Market Price  2019-09-03T04:30:00.000000000Z   \n",
       "\n",
       "   GMT Offset            Type   Open   High    Low   Last     Volume  \n",
       "0           7  Intraday 15Min    NaN    NaN    NaN    NaN        NaN  \n",
       "1           7  Intraday 15Min  43.50  43.75  43.50  43.75   463600.0  \n",
       "2           7  Intraday 15Min  43.50  43.75  43.25  43.50  4247200.0  \n",
       "3           7  Intraday 15Min  43.50  43.50  43.25  43.25   431900.0  \n",
       "4           7  Intraday 15Min  43.50  43.50  43.25  43.25   453600.0  \n",
       "5           7  Intraday 15Min  43.25  43.50  43.25  43.50   790900.0  \n",
       "6           7  Intraday 15Min  43.25  43.50  43.25  43.50   128700.0  \n",
       "7           7  Intraday 15Min  43.50  43.50  43.25  43.25   218200.0  \n",
       "8           7  Intraday 15Min  43.25  43.50  43.25  43.50  2358900.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "timeSeries = pd.read_csv(StringIO(uncompressedData))\n",
    "timeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [TRTH or Thomson Reuters Tick History](https://en.wikipedia.org/wiki/Representational_state_transfer) \n",
    "- [DataScope Select platform or DSS](https://developers.refinitiv.com/datascope-select-dss)\n",
    "- [REST API](https://en.wikipedia.org/wiki/Representational_state_transfer)\n",
    "- [REST API Reference Tree](https://hosted.datascopeapi.reuters.com/RestApi.Help/Home/RestApiProgrammingSdk)\n",
    "- [Advisory: Directly Downloading from Amazon Generates Error](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=25898&type=documentation_item)\n",
    "- [Advisory: Avoid Incomplete Output - Download then Decompress](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=22738&type=documentation_item)\n",
    "- [REST API Tutorial 3: On Demand data extraction workflow](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/learning?content=11307&type=learning_material_item)\n",
    "- [REST API Tutorial 6: On Demand intraday bars extraction](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/learning?content=11243&type=learning_material_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
