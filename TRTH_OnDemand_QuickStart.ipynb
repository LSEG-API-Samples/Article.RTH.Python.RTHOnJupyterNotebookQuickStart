{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick History on Jupyter Notebook Quick Start\n",
    "\n",
    "This article will demonstrate how to request tick history data on demand on Jupyter Notebook.\n",
    "\n",
    "## What is Tick History?\n",
    "\n",
    "[Tick History or TRTH](https://developers.refinitiv.com/thomson-reuters-tick-history-trth)  is an Internet-hosted product on [DataScope Select platform or DSS](https://developers.refinitiv.com/datascope-select-dss). TRTH is a historical market data service, offering global data dating back to January 1996, for example, intraday summaries, end of days prices, time and sales, market depth and raw data. TRTH provides [REST API](https://phpenthusiast.com/blog/what-is-rest-api) to access all data. In this article, I will demonstrate how to retrieve intraday summaries using an on demand request.\n",
    "\n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/TRTH_80.png\"  height=\"525\" width=\"389\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Python 3.6 or higher\n",
    "- Jupyter Notebook\n",
    "- DSS username and password which is permissioned for TRTH content. To obtain DSS account, please contact Refinitiv account team for process and details.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The steps and Python source code to request TRTH content on demand are listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Request authentication token with DSS username and password.\n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step1_70.png\"  height=\"564\" width=\"497\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Send HTTP post with DSS username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass as gp\n",
    "import requests\n",
    "import json\n",
    "\n",
    "username=input('Enter DSS username:')\n",
    "password=gp.getpass('Enter DSS Password:')\n",
    "\n",
    "requestUrl = \"https://hosted.datascopeapi.reuters.com/RestApi/v1/Authentication/RequestToken\"\n",
    "requestHeaders={\n",
    "    \"Prefer\":\"respond-async\",\n",
    "    \"Content-Type\":\"application/json\"\n",
    "    }\n",
    "requestBody={\n",
    "    \"Credentials\": {\n",
    "    \"Username\": username,\n",
    "    \"Password\": password\n",
    "  }\n",
    "}\n",
    "authenticationResp = requests.post(requestUrl, json=requestBody,headers=requestHeaders)\n",
    "print(\"the application received the response for authentication request.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check if the status code of the response is 200. If yes, the request has succeeded so the application extracts and prints the authentication token. Otherwise, it prints the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if authenticationResp.status_code == 200 :\n",
    "    print(\"The application received the response with HTTP status 200. It will get the authentication token from the response.\")\n",
    "    jsonResponse = json.loads(authenticationResp.text.encode('ascii', 'ignore'))\n",
    "    token = jsonResponse[\"value\"]\n",
    "    print ('Authentication token (valid 24 hours):')\n",
    "    print (token)\n",
    "else:\n",
    "    print(\"Error with Status Code:\",authenticationResp.status_code,\"\\n Text:\",json.dumps(json.loads(authenticationResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Request for data type using the received authentication token \n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step2_70.png\" height=\"497\" width=\"564\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Send HTTP post with on demand extraction request to request for data type. \n",
    " \n",
    "   The applications requests for intraday summaries. For more details of the others tick history data types (reports) and their fields, please see in [Data Dictionary - Custom Reporting](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=40731&type=documentation_item)  \n",
    "  \n",
    "   You can see all parameters of each data type in **REST API Reference Tree** at **https://hosted.datascopeapi.reuters.com/RestApi.Help/Home/RestApiProgrammingSdk**. You need to login with DSS username and password to access this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestUrl='https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/ExtractRaw'\n",
    "requestHeaders={\n",
    "    \"Prefer\":\"respond-async\",\n",
    "    \"Content-Type\":\"application/json\",\n",
    "    \"Authorization\": \"token \" + token\n",
    "}\n",
    "requestBody={\n",
    "  \"ExtractionRequest\": {\n",
    "    \"@odata.type\": \"#ThomsonReuters.Dss.Api.Extractions.ExtractionRequests.TickHistoryIntradaySummariesExtractionRequest\",\n",
    "    \"ContentFieldNames\": [\"Open\",\"High\",\"Low\",\"Last\",\"Volume\"],\n",
    "    \"IdentifierList\": {\n",
    "      \"@odata.type\": \"#ThomsonReuters.Dss.Api.Extractions.ExtractionRequests.InstrumentIdentifierList\",  \n",
    "      \"InstrumentIdentifiers\": [\n",
    "        {\"Identifier\": \"ADVANC.BK\", \"IdentifierType\": \"Ric\"},\n",
    "        {\"Identifier\": \"PTT.BK\", \"IdentifierType\": \"Ric\"} \n",
    "      ],\n",
    "      \"UseUserPreferencesForValidationOptions\":\"false\"    \n",
    "    },  \n",
    "    \"Condition\": {\n",
    "      \"MessageTimeStampIn\": \"GmtUtc\",\n",
    "      \"ReportDateRangeType\": \"Range\",\n",
    "      \"QueryStartDate\": \"2019-09-03T09:30:00.000Z\",\n",
    "      \"QueryEndDate\":   \"2019-09-03T17:00:00.000Z\",\n",
    "      \"SummaryInterval\": \"OneHour\",\n",
    "      \"DisplaySourceRIC\":\"true\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "extractionResp = requests.post(requestUrl, json=requestBody,headers=requestHeaders)\n",
    "print(\"the application received the response for on demand extraction request.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Check the request status untill the request has been processed completely.\n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step3_70.png\" height=\"497\" width=\"564\">\n",
    " \n",
    "- If the HTTP status code of response is 202 this means the extraction request was accepted, but processing has not completed yet. Hence, the application gets the received location url from 202 response header received in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requestStatus =  extractionResp.status_code\n",
    "print(\"The application received the response with HTTP status \" + str(requestStatus) + \".\")\n",
    "requestUrl=None\n",
    "if requestStatus == 202 :\n",
    "    requestUrl = extractionResp.headers[\"location\"]\n",
    "    print ('Extraction is not complete, the application will poll the location URL:')\n",
    "    print (str(requestUrl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While the status of the extraction request is 202, poll the request status every 30 seconds using the location url got from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while (requestStatus == 202):\n",
    "    print ('The application received a 202, it waits 30 seconds, then poll again until it does not receive 202.')\n",
    "    time.sleep(30)\n",
    "    extractionResp = requests.get(requestUrl,headers=requestHeaders)\n",
    "    requestStatus= extractionResp.status_code\n",
    "print ('The application received the HTTP response which status is not 202.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the request is completed (The HTTP status code is not 202), check the status code. If it is 200 or OK, the application gets and prints the results which are jobId and the extraction notes. The jobId is used to retrieve the data while the extraction can be used to analyze data or troubleshooting problems. Apart from the HTTP status code 200, it is an error and the application prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if requestStatus == 200 :\n",
    "    print(\"The application received response with HTTP status 200.It will get the JobId and Extraction notes.\")\n",
    "    extractionRespJson = json.loads(extractionResp.text.encode('ascii', 'ignore'))\n",
    "    jobId = extractionRespJson[\"JobId\"]\n",
    "    print ('\\njobId: ' + jobId + '\\n')\n",
    "    notes = extractionRespJson[\"Notes\"]\n",
    "    print ('Extraction notes:\\n' + notes[0])\n",
    "else:\n",
    "    print(\"Error with Status Code:\",extractionResp.status_code,\"\\n Text:\",json.dumps(json.loads(extractionResp.text),indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Retrieve data from TRTH or AWS\n",
    " <img src=\"https://raw.githubusercontent.com/Refinitiv-API-Samples/Article.TRTH.Python.TRTHOnJupyterNotebookQuickStart/master/figures/Step4_70.png\" height=\"497\" width=\"564\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Send HTTP get with a JobID got from the 200 OK response to retrieve data from TRTH or AWS \n",
    "\n",
    "   TRTH provides downloading some extraction data directly from Amazon Web Services (AWS) where the data files are hosted. The tick history data types which are supported by this feature are:\n",
    "    * Time and Sales\n",
    "    * Market Depth\n",
    "    * Intraday Summaries\n",
    "    * Raw.\n",
    "\n",
    "  This sample requests for intraday summaries which supports AWS download.  Therefore, I will download data from AWS which provides faster download speed than TRTH directly. The application must include the HTTP header field **X-Direct-Download: true** to specify for the download to occur through AWS. When the application sends the request with **X-Direct-Download: true** header, it will receive a response with HTTP status 302 or redirect. The response header contains a redirection URI in item Location. Fortunately, Python application automatically follows the redirection so the application has nothing to do. A call is made in the background to this URI and the data is retrieved. \n",
    "  If you application does not perform redirection automatically, please follows [Advisory: Directly Downloading from Amazon Generates Error](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=25898&type=documentation_item) how to perform redirection manually and to protect the error from AWS download.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DownloadFromAWS=True\n",
    "requestUrl=\"https://hosted.datascopeapi.reuters.com/RestApi/v1/Extractions/RawExtractionResults\" + \"('\" + jobId + \"')\" + \"/$value\"\n",
    "requestHeaders={\n",
    "        \"Prefer\":\"respond-async\",\n",
    "        \"Content-Type\":\"text/plain\",\n",
    "        \"Accept-Encoding\":\"gzip\",\n",
    "        \"Authorization\": \"token \" + token\n",
    "}\n",
    "if DownloadFromAWS==True:\n",
    "    requestHeaders.update({\"X-Direct-Download\":\"true\"})\n",
    "dataRetrieveResp=requests.get(requestUrl,headers=requestHeaders,stream=True)\n",
    "print(\"the application received the response for retreiving data using the jobId.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the status is 200 or OK that means the application can retrieve data from TRTH or AWS successfully. Otherwise, it prints the error and exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataRetrieveResp.status_code == 200 :\n",
    "    print(\"The application received the response with HTTP status 200. It retrieved data from the server successfully.\")\n",
    "else:\n",
    "    print(\"Error with Status Code:\",extractionResp.status_code,\"\\n Text:\",json.dumps(json.loads(extractionResp.text),indent=4))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You should save the downloaded data before decompressing it instead of decompressing it on the fly. This is to avoid data lost issues especially with large data sets. For more information, please refer to [Advisory: Avoid Incomplete Output - Download then Decompress](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=22738&type=documentation_item)\n",
    "\n",
    "   In Python, you can ensure that the data is not automatically decompressed on the fly by setting **requests.Response.raw.decode_content** to be **false**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "dataRetrieveResp.raw.decode_content = False\n",
    "fileName= os.getcwd() + \"\\compressData.csv.gz\" \n",
    "print ('Saving compressed data to file:' + fileName + ' ... please be patient')\n",
    "\n",
    "chunk_size = 1024\n",
    "rr = dataRetrieveResp.raw\n",
    "with open(fileName, 'wb') as fd:\n",
    "    shutil.copyfileobj(rr, fd, chunk_size)\n",
    "fd.close\n",
    "\n",
    "print ('Finished saving compressed data to file:' + fileName + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In production, you should handle the data line by line instead of store all the data in one variable. This is to avoid issues with large data sets.\n",
    "  \n",
    "  To display some data lines, the application reads and decompresses some lines in the data file just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "maxLines = 10\n",
    "print ('Read data from file, and decompress at most ' + str(maxLines) + ' lines of it:')\n",
    "uncompressedData = \"\"\n",
    "count = 0\n",
    "with gzip.open(fileName, 'rb') as fd:\n",
    "    for line in fd:\n",
    "        dataLine = line.decode(\"utf-8\")\n",
    "        print (dataLine)\n",
    "        uncompressedData = uncompressedData + dataLine\n",
    "        count += 1\n",
    "        if count > maxLines:\n",
    "            break\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This article explains how to request tick history data on demand from TRTH via REST API on Jupyter Notebook step by step. It demonstrates how to retrieve data from TRTH and AWS which provides faster download speed than TRTH. It also mentions the ways to avoid data lost issues with Python sample source code. Therefore, \n",
    "you can use the techniques explained in this article with other programming languages to request for any tick history data types and handle data without losing data issues. \n",
    "\n",
    "# References\n",
    "For further details, please check out the following resources:\n",
    "- [TRTH or Thomson Reuters Tick History](https://en.wikipedia.org/wiki/Representational_state_transfer) \n",
    "- [DataScope Select platform or DSS](https://developers.refinitiv.com/datascope-select-dss)\n",
    "- [REST API](https://phpenthusiast.com/blog/what-is-rest-api)\n",
    "- [REST API Reference Tree](https://hosted.datascopeapi.reuters.com/RestApi.Help/Home/RestApiProgrammingSdk)\n",
    "- [Advisory: Directly Downloading from Amazon Generates Error](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=25898&type=documentation_item)\n",
    "- [Advisory: Avoid Incomplete Output - Download then Decompress](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/docs?content=22738&type=documentation_item)\n",
    "- [REST API Tutorial 3: On Demand data extraction workflow](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/learning?content=11307&type=learning_material_item)\n",
    "- [REST API Tutorial 6: On Demand intraday bars extraction](https://developers.refinitiv.com/thomson-reuters-tick-history-trth/thomson-reuters-tick-history-trth-rest-api/learning?content=11243&type=learning_material_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
